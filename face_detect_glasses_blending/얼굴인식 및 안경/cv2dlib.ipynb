{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UNEtIMGAzpjf",
        "outputId": "f0e92b3c-1470-4075-e08c-dfb5119fdc5a"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'dlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdlib\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpatches\u001b[39;00m \u001b[39mimport\u001b[39;00m cv2_imshow\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "def detect_face(image_path):\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "  img = cv2.imread(image_path)\n",
        "  faces = detector(img, 1)\n",
        "  for face in faces:\n",
        "    left_top = (face.left(), face.top())\n",
        "    right_bottom = (face.right(), face.bottom())\n",
        "    cv2.rectangle(img, left_top, right_bottom, (0,0,255),2) #bgr\n",
        "  \n",
        "  cv2_imshow(img)\n",
        " \n",
        "\n",
        "def face_detect(image):\n",
        "  left_top = (0,0)\n",
        "  right_bottom = (0,0)\n",
        "\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  face_rect_list = detector(image, 1)\n",
        "\n",
        "  if len(face_rect_list) > 0:\n",
        "    face_rect = face_rect_list[0]\n",
        "    left_top = (face_rect.left(), face_rect.top())\n",
        "    right_bottom = (face_rect.right(), face_rect.bottom())\n",
        "\n",
        "  return left_top, right_bottom\n",
        "\n",
        "def face_sample(img):\n",
        "  image = cv2.imread(img)\n",
        "  lt, rb = face_detect(image)\n",
        "  cv2.rectangle(image, lt, rb, (0,0,255), thickness=1)\n",
        "  cv2_imshow(image)\n",
        "\n",
        "def face_detect_multi(image):\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  face_rect_list = detector(image, 1)\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for face_rect in face_rect_list:\n",
        "    left_top = (face_rect.left(), face_rect.top())\n",
        "    right_bottom = (face_rect.right(), face_rect.bottom())\n",
        "    results.append((left_top, right_bottom))\n",
        "\n",
        "  return results\n",
        "\n",
        "def face_sample1(img):\n",
        "  image = cv2.imread(img)\n",
        "  for lt, rb in face_detect_multi(image):\n",
        "    print(lt, rb)\n",
        "    cv2.rectangle(image, lt, rb, (0,0,255), thickness=1)\n",
        "    # cv2.circle(image, ((lt + rb)/2), ((rb-lt)/2), (0,0,255), thickness=1)\n",
        "    #cv2.circle(img, center, radius, color, thickness)\n",
        "  cv2_imshow(image)\n",
        "  \n",
        "\n",
        "def draw_landmark_point(image_path): #point 추가\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  predictor = dlib.shape_predictor('/content/shape_predictor_68_face_landmarks.dat')\n",
        "  \n",
        "\n",
        "  img = cv2.imread(image_path)\n",
        "  faces = detector(img, 1)\n",
        "  for face in faces:\n",
        "    shape = predictor(img, face)\n",
        "    for x in range(68):\n",
        "      pts = (shape.part(x).x, shape.part(x).y)\n",
        "      cv2.circle(img, pts, 1, (255,0,0), cv2.FILLED, cv2.LINE_AA)\n",
        "    cv2_imshow(img)\n",
        "   \n",
        "\n",
        "def draw_landmark(image_path):\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  predictor = dlib.shape_predictor('/content/shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "  image = cv2.imread(image_path)\n",
        "\n",
        "  for face_rect in detector(image, 0):\n",
        "    shape = predictor(image, face_rect)\n",
        "    for x in range(68):\n",
        "      pts = (shape.part(x).x, shape.part(x).y)\n",
        "      cv2.circle(image, pts, 1, (255,0,0),cv2.FILLED, cv2.LINE_AA)\n",
        "      cv2.putText(image, f\"{x}\", pts, cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
        "  \n",
        "  cv2_imshow(image)\n",
        "\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"/content/shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "def detect_faces(img):\n",
        "  result = []\n",
        "  for face_rect in detector(img, 1):\n",
        "    shape = predictor(img, face_rect)\n",
        "    result.append(shape)\n",
        "  return result\n",
        "\n",
        "\n",
        "\n",
        "def blend_glasses(image, glasses, faces):\n",
        "  for face in faces:\n",
        "    angle = calculate_face_angle(face)\n",
        "    glasses = rotate(glasses, angle)\n",
        "    glasses_shape = glasses.shape\n",
        "\n",
        "    glasses_width = int((face.part(45).x - face.part(36).x) * 1.4)\n",
        "    left = int(face.part(36).x - glasses_width * 0.15)\n",
        "    glass_height = int(glasses_width / glasses_shape[1] * glasses_shape[0])\n",
        "    top = int((face.part(36).y + face.part(45).y) / 2 - glass_height / 2.5)\n",
        "\n",
        "    glasses = cv2.resize(glasses, (glasses_width, int(glasses_width / 240 * 112)))\n",
        "    alpha = cv2.cvtColor(glasses[:,:,3], cv2.COLOR_GRAY2BGR) / 255.0\n",
        "    image[top:top+glasses.shape[0], left:left+glasses.shape[1],:3] = \\\n",
        "    (1.0 - alpha) * image[top:top+glasses.shape[0], left:left+glasses.shape[1], :3] + alpha * glasses[:,:,:3]\n",
        "\n",
        "    cv2_imshow(image)\n",
        "  \n",
        "\n",
        "def calculate_face_angle(face):\n",
        "  x = int(face.part(36).x - face.part(45).x)\n",
        "  y = int(face.part(36).y - face.part(45).y)\n",
        "  angle = np.arctan2(y, x) * -180 / np.pi\n",
        "  return angle\n",
        "\n",
        "def rotate(img, angle, scale = 1.0):\n",
        "  h,w,_ = img.shape\n",
        "  center = (w // 2, h // 2)\n",
        "  M = cv2.getRotationMatrix2D(center, angle, scale)\n",
        "\n",
        "  cos = np.abs(M[0,0])\n",
        "  sin = np.abs(M[0,1])\n",
        "  newW = int((h * sin) + (w * cos))\n",
        "  newH = int((h * cos) + (w * sin))\n",
        "\n",
        "  M[0,2] += (newW / 2) - center[0]\n",
        "  M[1,2] += (newH / 2) - center[1]\n",
        "\n",
        "  rotated_img = cv2.warpAffine(img, M, (newW, newH))\n",
        "  return rotated_img\n",
        "\n",
        "## alpha + glassess[:,:,3]\n",
        "\n",
        "\n",
        "  # center  = (img.shape[1] // 2, img.shape[0] // 2)\n",
        "  # M = cv2.getRotationMatrix2D(center, angle, scale)\n",
        "\n",
        "  # rotated_img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
        "  # return rotated_img\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # img = \"/content/사진.webp\" #한소희\n",
        "  # img = '/content/model.jpeg'\n",
        "  # img = \"/content/1636172328831.jpeg\"\n",
        "  # img = \"/content/사진3.jpeg\" #뉴진스\n",
        "  detect_face(\"/content/사진3.jpeg\")\n",
        "  # face_sample(img)\n",
        "  # face_detect_multi(img)\n",
        "  # face_sample1(img)\n",
        "  image = cv2.imread(\"/content/사진3.jpeg\")\n",
        "  faces = detect_faces(image)\n",
        "  glasses = cv2.imread(\"/content/glasses.png\", cv2.IMREAD_UNCHANGED)\n",
        "  # draw_landmark(img)\n",
        "  blend_glasses(image, glasses, faces)\n",
        "\n",
        "  rotated_glasses = rotate(glasses, 30)\n",
        "  cv2_imshow(rotated_glasses)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uhpgsk70eAD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
